import re
import os
import glob
import zipfile
import requests
from urllib.request import urlretrieve
import json
import pandas as pd
import seaborn as sns
sns.set(rc={'figure.figsize':(11.7,8.27),"font.size":20,"axes.titlesize":20,"axes.labelsize":20},style="white") 
import matplotlib.pyplot as plt


article_id = 14096681 
url = f"https://api.figshare.com/v2/articles/{article_id}"
headers = {"Content-Type": "application/json"}
output_directory = "figshareaustralia/"

response = requests.request("GET", url, headers=headers)
data = json.loads(response.text) 
files = data["files"]             
files


get_ipython().run_cell_magic("time", "", """files_to_dl = ["data.zip"] 
for file in files:
    if file["name"] in files_to_dl:
        os.makedirs(output_directory, exist_ok=True)
        urlretrieve(file["download_url"], output_directory + file["name"])""")


get_ipython().run_cell_magic("time", "", """with zipfile.ZipFile(os.path.join(output_directory, "data.zip"), 'r') as f:
    f.extractall(output_directory)""")


get_ipython().run_cell_magic("sh", "", """ls -ltr figshareaustralia/""")


get_ipython().run_cell_magic("time", "", """files = glob.glob('figshareaustralia/*.csv')
files.remove('figshareaustralia\\observed_daily_rainfall_SYD.csv')

df = pd.concat((pd.read_csv(file, index_col=0)
                .assign(model=file.split('\\')[1].split('_daily')[0])
                for file in files)
              )
df.to_csv("figshareaustralia/combined_data.csv")""")


files = glob.glob('figshareaustralia/*.csv')
files = ['figshareaustralia\\CanESM5_daily_rainfall_NSW.csv',
 'figshareaustralia\\BCC-ESM1_daily_rainfall_NSW.csv',
 'figshareaustralia\\NESM3_daily_rainfall_NSW.csv']
df = pd.concat((pd.read_csv(file, index_col=0)
                .assign(model=file.split('\\')[1].split('_daily')[0])
                for file in files)
              )
df.to_csv("figshareaustralia/small_data.csv")





df.head(3)


init = df['lat_min'].unique()


df['lat_dif'] = df['lat_max'] - df['lat_min']
df['lon_dif'] = df['lon_max'] - df['lon_min']
df['lat_avg'] =  df[['lat_min', 'lat_max']].mean(axis=1)
df['lon_avg'] =  df[['lon_min', 'lon_max']].mean(axis=1)


df['lat_dif'].unique()


df['lon_dif'].unique()


df1 = df.loc[df['lat_dif']==1.875]


df2 = df.loc[df['lat_dif']!=1.875]


df1


plt.figure(figsize=(10,10))
sns.scatterplot(x=df1['lat_avg'],
                y=df1['lon_avg'],
                hue=df1['rain (mm/day)'],
                marker="s", 
                size=100,
                palette='turbo')


df.shape


np.diff(init)


#Size of dataframe
df.shape


# Number of models
len(df['model'].unique())


#After preliminary high level cleaning of data, we have only NaN data for 'name' feature, which will be dropped anyway later. Thus
#we should not do any imputation
df[df.isnull().any(axis=1)]


df = df.dropna()


df.head()


df[]


plt.figure(figsize=(20,10))
sns.violinplot(data=train_df, x = 'neighbourhood_group', y = 'reviews_per_month', palette='turbo')


plt.figure(figsize=(10,10))
sns.scatterplot(x=train_df['longitude'], y=train_df['latitude'],
                hue=train_df['reviews_per_month'], palette='turbo')


fig, ax =plt.subplots(1,2, figsize=(20,10))
sns.scatterplot(x=train_df['longitude'], y=train_df['latitude'],
                hue=train_df['neighbourhood_group'], palette='Set2', ax=ax[0])
sns.scatterplot(x=train_df['longitude'], y=train_df['latitude'],
                hue=train_df['log_price_truncated'], palette='turbo', ax=ax[1])


import matplotlib.pyplot as plt
from matplotlib import colors
import numpy as np

data = np.random.rand(3, 3) * 20

# create discrete colormap
cmap = colors.ListedColormap(['red', 'blue'])
bounds = [0,10,20]
norm = colors.BoundaryNorm(bounds, cmap.N)

fig, ax = plt.subplots()
ax.imshow(data, cmap=cmap, norm=norm)

# # draw gridlines
# ax.grid(which='major', axis='both', linestyle='-', color='k', linewidth=2)
# ax.set_xticks(np.arange(-.5, 10, 1));
# ax.set_yticks(np.arange(-.5, 10, 1));

# plt.show()


data


df_mavg = df.resample('M').mean()



